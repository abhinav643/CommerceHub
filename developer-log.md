# Developer Log – AI Augmented Development

## AI Strategy

I used AI tools mainly to speed up development while keeping full control over the system design and implementation decisions.

Before asking AI to generate any code, I provided clear context about the domain and requirements, including:

- Product and Order data models  
- API endpoint behaviors and expected request/response flows  
- Concurrency requirements for safe inventory updates  
- Rules for publishing events through RabbitMQ  
- Validation logic and unit testing expectations  

To ensure the generated code followed a clean and maintainable structure, I explicitly instructed AI to use a layered architecture pattern:

Controller → Service → Repository → Infrastructure

This helped maintain separation of concerns and made the system easier to extend and test.

For critical areas like inventory updates, I guided AI to implement MongoDB atomic operations instead of read-then-write logic, since preventing race conditions was a key requirement of the assignment.

Throughout development, I reviewed AI-generated code carefully and refined it where needed, especially to enforce proper error handling, rollback behavior, and ensuring that events were only published after an order was successfully persisted.

Overall, AI was primarily used to generate initial scaffolding and boilerplate code, while architectural decisions, concurrency handling, and final validation were directed and verified manually.

---

## Human Audit & Corrections

### 1. Fixing Concurrency Risk in Stock Updates

The initial code generated by AI used a read-then-write pattern for updating product stock. This meant the system would first fetch the current stock and then perform a separate update. I recognized that this approach could lead to race conditions under concurrent requests, potentially allowing stock to go negative.

To fix this, I implemented a guarded atomic update using a single MongoDB `UpdateOne` operation with a condition (`stock >= quantity`). This ensures that inventory updates remain safe even when multiple checkout requests happen at the same time.


### 2. Updating RabbitMQ Code for Client Version Compatibility

AI generated event publishing code using the older `IModel` interface. During implementation, I noticed that the project was using RabbitMQ.Client v7, which replaces `IModel` with the `IChannel` interface and uses async publishing methods.

I updated the code to use the correct API, ensuring successful message publishing and compatibility with the newer RabbitMQ client library.


### 3. Fixing Docker Build Failure

The Dockerfile initially restored dependencies using the solution file. This caused build failures because the test project was referenced but not included in the container image.

I corrected this by restoring dependencies using the API project file instead of the solution file. This resolved the build issue and produced a working container image.


### 4. Resolving MongoDB Field Naming Issues

AI-generated repository logic assumed strongly typed field mappings, but the seeded MongoDB documents used camelCase field names. This caused update filters to fail silently.

I fixed this by registering MongoDB camelCase conventions so that the C# models and database documents used consistent field naming, which restored correct update behavior.

---

## Verification Using AI

AI was used to help generate ideas for unit tests, especially for edge cases that are easy to miss during normal development.

With AI assistance, I created test scenarios such as:

- Validation failures for invalid input, including negative order quantities  
- Multi-item checkout cases where one product update succeeds but a later update fails, requiring rollback of previously decremented stock  
- Verifying that OrderCreated events are published only after successful order persistence and are never emitted when checkout fails  

All AI-generated test suggestions were reviewed manually to ensure they matched the actual business logic and concurrency behavior of the system.

The final test suite covers both successful flows and failure scenarios, helping confirm that the system behaves correctly under edge cases and maintains data consistency.

